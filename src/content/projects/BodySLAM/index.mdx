---
type: 'project'
slug: BodySLAM
title: BodySLAM
subtitle: Opportunistic User Digitization in Multi-User AR/VR Experiences
authors:
  - Karan Ahuja
  - Mayank Goel
  - Chris Harrison
year: 2020
coverImage: './images/cover.png'
published: 'yes'
award:
pdfLink: '/papers/bodyslam.pdf'
github:
videoLink: https://www.youtube.com/embed/reSqz3H7yP8?si=MlPN690jY3KdKhmq
conference: "SUI '20: Proceedings of the 2020 ACM Symposium on Spatial User Interaction"
conferencePage: 'https://doi.org/10.1145/3385959.3418452'
citation: 'Ahuja, K., Goel, M., & Harrison, C. (2020, October). BodySLAM: Opportunistic user digitization in multi-user AR/VR Experiences. In Proceedings of the 2020 ACM Symposium on Spatial User Interaction (pp. 1-8).'
bibtex: |
  @inproceedings{ahuja2020bodyslam,
    title={BodySLAM: Opportunistic user digitization in multi-user AR/VR Experiences},
    author={Ahuja, Karan and Goel, Mayank and Harrison, Chris},
    booktitle={Proceedings of the 2020 ACM Symposium on Spatial User Interaction},
    pages={1--8},
    year={2020}
  }
---

## Abstract

Todayâ€™s augmented and virtual reality (AR/VR) systems do not provide body, hand or mouth tracking without special worn sensors or external infrastructure. Simultaneously, AR/VR systems are increasingly being used in co-located, multi-user experiences, opening the possibility for opportunistic capture of other users. This is the core idea behind BodySLAM, which uses disparate camera views from users to digitize the body, hands and mouth of other people, and then relay that information back to the respective users. If a user is seen by two or more people, 3D pose can be estimated via stereo reconstruction. Our system also maps the arrangement of users in real-world coordinates. Our approach requires no additional hardware or sensors beyond what is already found in commercial AR/VR devices, such as Microsoft HoloLens or Oculus Quest.
