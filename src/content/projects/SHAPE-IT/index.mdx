---
type: 'project'
slug: SHAPE-IT
title: SHAPE-IT
subtitle: Exploring Text-to-Shape-Display for Generative Shape-Changing Behaviors with LLMs
authors:
  - Wanli Qian*
  - Chenfeng Gao*
  - Anup Sathya
  - Ryo Suzuki
  - Ken Nakagaki

year: 2024
dateAdded: "2024-08-01"
coverImage: './images/cover.png'
published: 'no'
ishomePage: 'yes'
award:
pdfLink: '/pdfs/project1.pdf'
github: 'https://github.com/SPICExLAB/MobilePoser'
videoLink:
previewLink:
conference: "UIST '24: Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology"
conferencePage: 'https://dl.acm.org/doi/10.1145/3491102.3502069'
citation: " "
bibtex: |

---

## Abstract

This paper introduces text-to-shape-display, a novel approach to generating dynamic shape changes in pin-based shape displays through natural language commands. By leveraging large language models (LLMs) and AI-chaining, our approach allows users to author shape-changing behaviors on demand through text prompts without programming. We describe the foundational aspects necessary for such a system, including the identification of key generative elements (primitive, animation, and interaction) and design requirements to enhance user interaction, based on formative exploration and iterative design processes. Based on these insights, we develop SHAPE-IT, an LLM-based authoring tool for a 24 x 24 shape display, which translates the user's textual command into executable code and allows for quick exploration through a web-based control interface. We evaluate the effectiveness of SHAPE-IT in two ways: 1. performance evaluation and 2. user evaluation (N= 10). The study conclusions highlight the ability to facilitate rapid ideation of a wide range of shape-changing behaviors with AI. However, the findings also expose accuracy-related challenges and limitations, prompting further exploration into refining the framework for leveraging AI to better suit the unique requirements of shape-changing systems.


